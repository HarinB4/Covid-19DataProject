{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Demographic dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read csv file save it in dataframe\n",
    "demographic_covid_df = pd.read_csv(\"../../../data/output/covid.csv\")\n",
    "\n",
    "# save dataframe to csv file and remove headers like \"DP_04M\"\n",
    "demographic_covid_df.to_csv('Demographic.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Demographic Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>Statewide Unallocated</th>\n",
       "      <th>AL</th>\n",
       "      <th>0.2</th>\n",
       "      <th>1</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.6</th>\n",
       "      <th>...</th>\n",
       "      <th>0.530</th>\n",
       "      <th>0.531</th>\n",
       "      <th>0.532</th>\n",
       "      <th>0.533</th>\n",
       "      <th>0.534</th>\n",
       "      <th>0.535</th>\n",
       "      <th>0.536</th>\n",
       "      <th>0.537</th>\n",
       "      <th>0.538</th>\n",
       "      <th>0.539</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1001</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>AL</td>\n",
       "      <td>55869</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>27</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1003</td>\n",
       "      <td>Baldwin County</td>\n",
       "      <td>AL</td>\n",
       "      <td>223234</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>56</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 545 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   0.1 Statewide Unallocated  AL     0.2  1  0.3  0.4  0.5  0.6  ...  \\\n",
       "0  1  1001        Autauga County  AL   55869  1    0    0    0    0  ...   \n",
       "1  2  1003        Baldwin County  AL  223234  1    0    0    0    0  ...   \n",
       "\n",
       "   0.530  0.531  0.532  0.533  0.534  0.535  0.536  0.537  0.538  0.539  \n",
       "0     27     28     28     28     28     28     28     28     28     28  \n",
       "1     56     64     64     65     65     65     65     66     66     67  \n",
       "\n",
       "[2 rows x 545 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read csv file without header and save it in dataframe\n",
    "demographic_df = pd.read_csv(\"Demographic.csv\")\n",
    "demographic_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop unwanted columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns which shows margin of errors, percent estimate and percent margin of error \n",
    "\n",
    "demographic_df = demographic_df[demographic_df.columns.drop(list(demographic_df.filter(regex='Margin')))]\n",
    "demographic_df = demographic_df[demographic_df.columns.drop(list(demographic_df.filter(regex='Percent')))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split id and Geographica Area Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'id'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2896\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2897\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2898\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'id'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-ad726f184c9c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcounty_FIPS_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdemographic_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"id\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mcounty_FIPS_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdemographic_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2978\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2979\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2980\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2981\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2982\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2897\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2898\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2899\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2900\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2901\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'id'"
     ]
    }
   ],
   "source": [
    "#Select column \"id\" from Demographic_df, and choose a substring of each value in the column which contains county FIPS,\n",
    "#and append it to a list   \n",
    "\n",
    "county_FIPS_list = []\n",
    "for i in range(len(demographic_df[\"id\"])):\n",
    "    county_FIPS_list.append(demographic_df.loc[i,'id'][9:])\n",
    "    \n",
    "#Add the list as a new column to the Demographic_df     \n",
    "demographic_df[\"countyFIPS\"] = county_FIPS_list\n",
    "\n",
    "#Convert the type of countyFIPS from string to int\n",
    "demographic_df['countyFIPS'] = demographic_df['countyFIPS'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split geographical area name into county and state name\n",
    "\n",
    "demographic_df[['County Name','State']] = demographic_df[\"Geographic Area Name\"].str.split(\",\",expand=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographic_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In order to calcute correlation, read the confirmed cases and death datasets, and calculate the total number of confirmed cases and death for each county, merge them with Demographic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read csv confirmed cases file and save it in a dataframe\n",
    "confirmed_df = pd.read_csv(\"../../data/COVID-19 Dataset/confirmed.csv\")\n",
    "\n",
    "# Read csv death file and save it in a dataframe\n",
    "death_df = pd.read_csv(\"../../data/COVID-19 Dataset/deaths.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sum up confirmed cases for each county\n",
    "confirmed_df['Confirmed Total']= confirmed_df.iloc[:, 4:].sum(axis=1)\n",
    "\n",
    "#sum up death for each county\n",
    "death_df['death Total']= death_df.iloc[:, 4:].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a new dataframe for confirmed cases which contains \"countyFIPS\", \"County Name\", \"Confirmed Total\"\n",
    "modified_confirmed_df = confirmed_df[[\"countyFIPS\", \"County Name\",\"State\", \"Confirmed Total\"]]\n",
    "\n",
    "# define a new dataframe for death cases which contains \"countyFIPS\", \"County Name\", \"death Total\"\n",
    "modified_death_df = death_df[[\"countyFIPS\", \"County Name\", \"State\",\"death Total\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge modified dataframes based on \"countyFIPS\", \"County Name\"\n",
    "modified_confirmed_death_df = pd.merge(modified_confirmed_df,modified_death_df, on = [\"countyFIPS\", \"County Name\" ,\"State\"])\n",
    "\n",
    "modified_confirmed_death_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge modified_confirmed_death_df with demographic dataset and then calculate correlation of each column with total confirmed and total death of each county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge demographic df with modified_confirmed_death\n",
    "covid_demographic_ConfirmedDeath_df = pd.merge(modified_confirmed_death_df,demographic_df, on = [\"countyFIPS\"])\n",
    "covid_demographic_ConfirmedDeath_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a list which contains column headers of covid_demographic_ConfirmedDeath_df\n",
    "columns = covid_demographic_ConfirmedDeath_df.columns\n",
    "columns_modified = columns[8:-2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate correlation for each column with total Confirmed cases and then append it to a list\n",
    "correlation_confirmed = []\n",
    "for i in range(len(columns_modified)-1):\n",
    "    corr = covid_demographic_ConfirmedDeath_df[\"Confirmed Total\"].corr(covid_demographic_ConfirmedDeath_df[columns_modified[i]])\n",
    "    correlation_confirmed.append([columns_modified[i], corr])\n",
    "\n",
    "#Sort the list \n",
    "correlation_confirmed = sorted(correlation_confirmed, key=lambda x: -x[1])\n",
    "correlation_confirmed[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate correlation for each column with total death and then append it to a list\n",
    "correlation_death = []\n",
    "for i in range(len(columns_modified)-1):\n",
    "    corr = covid_demographic_ConfirmedDeath_df[\"death Total\"].corr(covid_demographic_ConfirmedDeath_df[columns_modified[i]])\n",
    "    correlation_death.append([columns_modified[i], corr])\n",
    "    \n",
    "#Sort the list \n",
    "correlation_death = sorted(correlation_death, key=lambda x: -x[1])\n",
    "correlation_death[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose important columns based on correlation values and define a new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum up \"under 5\" and \"5 to 9\"\n",
    "demographic_df[\"Estimate!!SEX AND AGE!!Total population!!Under 10 years\"]= demographic_df.iloc[:, 64:66].sum(axis=1)\n",
    "\n",
    "# sum up \"10 to 14\" and \"15 to 19\"\n",
    "demographic_df[\"Estimate!!SEX AND AGE!!Total population!!10 to 19 years\"] = demographic_df.iloc[:, 66:68].sum(axis=1)\n",
    "\n",
    "# sum up \"20 to 24\" and \"25 to 34\"\n",
    "demographic_df[\"Estimate!!SEX AND AGE!!Total population!!20 to 34 years\"] = demographic_df.iloc[:, 68:70].sum(axis=1)\n",
    "\n",
    "# sum up \"55 to 59\" and \"60 to 64\"\n",
    "demographic_df[\"Estimate!!SEX AND AGE!!Total population!!55 to 64 years\"] = demographic_df.iloc[:, 72:74].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographic_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographic_df_final = demographic_df[[\"countyFIPS\", \"Estimate!!SEX AND AGE!!Total population!!Under 10 years\",\n",
    "                                     \"Estimate!!SEX AND AGE!!Total population!!10 to 19 years\", \"Estimate!!SEX AND AGE!!Total population!!20 to 34 years\",\n",
    "                                     \"Estimate!!SEX AND AGE!!Total population!!35 to 44 years\", \"Estimate!!SEX AND AGE!!Total population!!45 to 54 years\",\n",
    "                                     \"Estimate!!SEX AND AGE!!Total population!!55 to 64 years\", \"Estimate!!SEX AND AGE!!Total population!!65 to 74 years\",\n",
    "                                     \"Estimate!!SEX AND AGE!!Total population!!75 to 84 years\", \"Estimate!!SEX AND AGE!!Total population!!85 years and over\",\n",
    "                                     \"Estimate!!SEX AND AGE!!Total population!!65 years and over!!Female\", \"Estimate!!SEX AND AGE!!Total population!!65 years and over!!Male\",\n",
    "                                     \"Estimate!!SEX AND AGE!!Total population!!Female\",\"Estimate!!SEX AND AGE!!Total population!!Male\",\n",
    "                                      \"Estimate!!RACE!!Total population!!One race!!White\",\"Estimate!!RACE!!Total population!!One race!!Black or African American\",\n",
    "                                     \"Estimate!!HISPANIC OR LATINO AND RACE!!Total population\", \"Estimate!!RACE!!Total population!!One race!!Asian\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographic_df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the main covid dataset and merge it with demographic_df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the covid dataset\n",
    "covid_df = pd.read_csv(\"../../data/output/covid.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge covid_df with demographic_df_final \n",
    "covid_demoghraphic_df = pd.merge(covid_df,demographic_df_final, on = \"countyFIPS\", how = \"left\")\n",
    "covid_demoghraphic_df = covid_demoghraphic_df.drop([\"Unnamed: 0\"], axis = 1)\n",
    "\n",
    "#display final dataframe\n",
    "covid_demoghraphic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the final datafram in csv file\n",
    "covid_demoghraphic_df.to_csv(\"../../data/output/COVID19_DEMOGRAPHIC_MERGE.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
