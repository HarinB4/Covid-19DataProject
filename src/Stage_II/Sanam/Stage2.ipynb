{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from operator import itemgetter\n",
    "import plotly.express as px\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 551 fields in line 3199, saw 555\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-e7061d7e971e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#read data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mcovid_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../../../data/output/covid.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mcovid_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcovid_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Unnamed: 0\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mcovid_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcovid_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcovid_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcovid_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'County Name'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"Statewide Unallocated\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    683\u001b[0m         )\n\u001b[0;32m    684\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    462\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 463\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    464\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    465\u001b[0m         \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1152\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1153\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nrows\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1154\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1156\u001b[0m         \u001b[1;31m# May alter columns / col_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   2057\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2058\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2059\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2060\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2061\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 551 fields in line 3199, saw 555\n"
     ]
    }
   ],
   "source": [
    "#read data\n",
    "\n",
    "covid_df = pd.read_csv(\"../../../data/output/covid.csv\")\n",
    "covid_df = covid_df.drop(\"Unnamed: 0\",axis =1)\n",
    "covid_df = covid_df.drop(covid_df.loc[covid_df['County Name'] == \"Statewide Unallocated\"].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'State'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-82c86034c14d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Groupby covid_df based on State\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mcovid_dfState\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcovid_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"State\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mcovid_dfState\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcovid_dfState\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"countyFIPS\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"stateFIPS\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mcovid_dfState\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mgroupby\u001b[1;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, observed, **kwargs)\u001b[0m\n\u001b[0;32m   7892\u001b[0m             \u001b[0msqueeze\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7893\u001b[0m             \u001b[0mobserved\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobserved\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 7894\u001b[1;33m             \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   7895\u001b[0m         )\n\u001b[0;32m   7896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001b[0m in \u001b[0;36mgroupby\u001b[1;34m(obj, by, **kwds)\u001b[0m\n\u001b[0;32m   2520\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"invalid type: {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2521\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2522\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mklass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, observed, **kwargs)\u001b[0m\n\u001b[0;32m    389\u001b[0m                 \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m                 \u001b[0mobserved\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobserved\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 391\u001b[1;33m                 \u001b[0mmutated\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmutated\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    392\u001b[0m             )\n\u001b[0;32m    393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\grouper.py\u001b[0m in \u001b[0;36m_get_grouper\u001b[1;34m(obj, key, axis, level, sort, observed, mutated, validate)\u001b[0m\n\u001b[0;32m    619\u001b[0m                 \u001b[0min_axis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgpr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    620\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 621\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    622\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGrouper\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mgpr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkey\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    623\u001b[0m             \u001b[1;31m# Add key to exclusions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'State'"
     ]
    }
   ],
   "source": [
    "#Groupby covid_df based on State\n",
    "\n",
    "covid_dfState = covid_df.groupby(\"State\").sum()\n",
    "covid_dfState = covid_dfState.drop([\"countyFIPS\", \"stateFIPS\"],axis =1)\n",
    "covid_dfState.reset_index(inplace=True)\n",
    "covid_dfState.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate weekly statistics (mean, median, mode) for number of cases and deaths across a specific state. Compare the data against other states."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I selected MA to generate weekly statistics. Then, I chose AZ, IN, MO, NJ, TN to compare their data with MA data. The reason that I selected those 5 states is that their population is similar to MA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select states AZ, IN, MO, NJ, TN\n",
    "\n",
    "covid_dfSt = covid_dfState.iloc[ [3,15,19,24,31,42] , : ]\n",
    "covid_dfSt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seperate Cases and Deaths\n",
    "\n",
    "StCases = covid_dfSt.filter(regex = \"x\")\n",
    "StDeaths = covid_dfSt.filter(regex = \"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate new Cases and deaths\n",
    "\n",
    "StNewCases = StCases.diff(axis = 1)\n",
    "StNewDeaths = StDeaths.diff(axis = 1)\n",
    "StNewCases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalizing new cases and new deaths per 1000000 people. Since population of each state is around 7000000, I selected 1000000 for normalizing my data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize new cases\n",
    "\n",
    "StNormCases = StNewCases.transpose()\n",
    "StNormCases[\"AZ Cases(Norm)\"] = ((StNormCases[3]/7278717)*1000000).round()\n",
    "StNormCases[\"IN Cases(Norm)\"] = ((StNormCases[15]/6732219)*1000000).round()\n",
    "StNormCases[\"MA Cases(Norm)\"] = ((StNormCases[19]/6892503)*1000000).round()\n",
    "StNormCases[\"MO Cases(Norm)\"] = ((StNormCases[24]/6137428)*1000000).round()\n",
    "StNormCases[\"NJ Cases(Norm)\"] = ((StNormCases[31]/8882190)*1000000).round()\n",
    "StNormCases[\"TN Cases(Norm)\"] = ((StNormCases[42]/6829174)*1000000).round()\n",
    "StNormCases.drop(columns =[3,15,19,24,31,42], inplace = True)\n",
    "\n",
    "\n",
    "# Normalize new deaths\n",
    "\n",
    "StNormDeaths = StNewDeaths.transpose()\n",
    "StNormDeaths[\"AZ Deaths(Norm)\"] = ((StNormDeaths[3]/7278717)*1000000).round()\n",
    "StNormDeaths[\"IN Deaths(Norm)\"] = ((StNormDeaths[15]/6732219)*1000000).round()\n",
    "StNormDeaths[\"MA Deaths(Norm)\"] = ((StNormDeaths[19]/6892503)*1000000).round()\n",
    "StNormDeaths[\"MO Deaths(Norm)\"] = ((StNormDeaths[24]/6137428)*1000000).round()\n",
    "StNormDeaths[\"NJ Deaths(Norm)\"] = ((StNormDeaths[31]/8882190)*1000000).round()\n",
    "StNormDeaths[\"TN Deaths(Norm)\"] = ((StNormDeaths[42]/6829174)*1000000).round()\n",
    "StNormDeaths.drop(columns =[3,15,19,24,31,42], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate weekly mean for new cases and new deaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Calculate mean for Normalized New Cases\n",
    "\n",
    "StNormCases_week = StNormCases.groupby(np.arange(len(StNormCases))//7).mean().round(0).astype(int).rename_axis('Week')\n",
    "StNormCases_week.columns = ['AZ', 'IN','MA','MO','NJ','TN']\n",
    "StNormCases_week = StNormCases_week.reset_index()\n",
    "StNormCases_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate mean for Normalized New Deaths\n",
    "\n",
    "StNormDeaths_week = StNormDeaths.groupby(np.arange(len(StNormDeaths))//7).mean().round(0).astype(int).rename_axis('Week')\n",
    "StNormDeaths_week.columns = ['AZ', 'IN','MA','MO','NJ','TN']\n",
    "StNormDeaths_week = StNormDeaths_week.reset_index()\n",
    "StNormDeaths_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean, Median and Mode for normalized new cases and new deaths. Value of mode for most of the states is zero. That's why, after calculating mode, I also write a code for ignoring zero and calculating mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Mean, Median, Mode for Normalized Cases\n",
    "\n",
    "AZNormCases_mean = round(StNormCases_week[\"AZ\"].mean())\n",
    "AZNormCases_median = round(StNormCases_week[\"AZ\"].median())\n",
    "AZNormCases_mode = StNormCases_week[\"AZ\"].mode()\n",
    "AZNormCases0_mode = StNormCases_week[\"AZ\"].replace(0, np.nan).mode()\n",
    "\n",
    "INNormCases_mean = round(StNormCases_week[\"IN\"].mean())\n",
    "INNormCases_median = round(StNormCases_week[\"IN\"].median())\n",
    "INNormCases_mode = StNormCases_week[\"IN\"].mode()\n",
    "INNormCases0_mode = StNormCases_week[\"IN\"].replace(0, np.nan).mode()\n",
    "\n",
    "MANormCases_mean = round(StNormCases_week[\"MA\"].mean())\n",
    "MANormCases_median = round(StNormCases_week[\"MA\"].median())\n",
    "MANormCases_mode = StNormCases_week[\"MA\"].mode()\n",
    "MANormCases0_mode = StNormCases_week[\"MA\"].replace(0, np.nan).mode()\n",
    "\n",
    "MONormCases_mean = round(StNormCases_week[\"MO\"].mean())\n",
    "MONormCases_median = round(StNormCases_week[\"MO\"].median())\n",
    "MONormCases_mode = StNormCases_week[\"MO\"].mode()\n",
    "MONormCases0_mode = StNormCases_week[\"MO\"].replace(0, np.nan).mode()\n",
    "\n",
    "NJNormCases_mean = round(StNormCases_week[\"NJ\"].mean())\n",
    "NJNormCases_median = round(StNormCases_week[\"NJ\"].median())\n",
    "NJNormCases_mode = StNormCases_week[\"NJ\"].mode()\n",
    "NJNormCases0_mode = StNormCases_week[\"NJ\"].replace(0, np.nan).mode()\n",
    "\n",
    "TNNormCases_mean = round(StNormCases_week[\"TN\"].mean())\n",
    "TNNormCases_median = round(StNormCases_week[\"TN\"].median())\n",
    "TNNormCases_mode = StNormCases_week[\"TN\"].mode()\n",
    "TNNormCases0_mode = StNormCases_week[\"TN\"].replace(0, np.nan).mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a list of lists for cases mean, median, mode\n",
    "\n",
    "Cases_statistics =[[AZNormCases_mean, INNormCases_mean, MANormCases_mean, MONormCases_mean, NJNormCases_mean,TNNormCases_mean],\n",
    "             [AZNormCases_median, INNormCases_median, MANormCases_median, MONormCases_median, NJNormCases_median, TNNormCases_median],\n",
    "             [AZNormCases_mode[0], INNormCases_mode[0], MANormCases_mode[0], MONormCases_mode[0], NJNormCases_mode[0], TNNormCases_mode[0]]]\n",
    "\n",
    "\n",
    "#Create a dataframe from list\n",
    "\n",
    "Cases_sta = pd.DataFrame(Cases_statistics, columns = ['AZ', 'IN', 'MA','MO', 'NJ', 'TN'], \n",
    "                         index=['Mean', 'Median', 'Mode'])  \n",
    "Cases_sta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### In all states mean is larger than median and mode is zero which means the distribution is right skewed.  Larger value of mean shows that there are a few larger value of new cases in the data which drives the mean upward, but they could not effect the median. The difference between mean and median in IN is not very big which shows that the distribution of new cases data can be assumed to be approximately symmetrical compare to other states. TN has the highest mean and MA lowest mean among other states. Since the data is normalized, we can conclude that MA has the lowest new cases and TN has the highest new Cases among other states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Mean, Median, Mode for normalized new Deaths\n",
    "\n",
    "AZNormDeaths_mean = round(StNormDeaths_week[\"AZ\"].mean())\n",
    "AZNormDeaths_median = round(StNormDeaths_week[\"AZ\"].median())\n",
    "AZNormDeaths_mode = StNormDeaths_week[\"AZ\"].mode()\n",
    "AZNormDeaths0_mode = StNormDeaths_week[\"AZ\"].replace(0, np.nan).mode()\n",
    "\n",
    "INNormDeaths_mean = round(StNormDeaths_week[\"IN\"].mean())\n",
    "INNormDeaths_median = round(StNormDeaths_week[\"IN\"].median())\n",
    "INNormDeaths_mode = StNormDeaths_week[\"IN\"].mode()\n",
    "INNormDeaths0_mode = StNormDeaths_week[\"IN\"].replace(0, np.nan).mode()\n",
    "\n",
    "MANormDeaths_mean = round(StNormDeaths_week[\"MA\"].mean())\n",
    "MANormDeaths_median = round(StNormDeaths_week[\"MA\"].median())\n",
    "MANormDeaths_mode = StNormDeaths_week[\"MA\"].mode()\n",
    "MANormDeaths0_mode = StNormDeaths_week[\"MA\"].replace(0, np.nan).mode()\n",
    "\n",
    "MONormDeaths_mean = round(StNormDeaths_week[\"MO\"].mean())\n",
    "MONormDeaths_median = round(StNormDeaths_week[\"MO\"].median())\n",
    "MONormDeaths_mode = StNormDeaths_week[\"MO\"].mode()\n",
    "MONormDeaths0_mode = StNormDeaths_week[\"MO\"].replace(0, np.nan).mode()\n",
    "\n",
    "NJNormDeaths_mean = round(StNormDeaths_week[\"NJ\"].mean())\n",
    "NJNormDeaths_median = round(StNormDeaths_week[\"NJ\"].median())\n",
    "NJNormDeaths_mode = StNormDeaths_week[\"NJ\"].mode()\n",
    "NJNormDeaths0_mode = StNormDeaths_week[\"NJ\"].replace(0, np.nan).mode()\n",
    "\n",
    "\n",
    "TNNormDeaths_mean = round(StNormDeaths_week[\"TN\"].mean())\n",
    "TNNormDeaths_median = round(StNormDeaths_week[\"TN\"].median())\n",
    "TNNormDeaths_mode = StNormDeaths_week[\"TN\"].mode()\n",
    "TNNormDeaths0_mode = StNormDeaths_week[\"TN\"].replace(0, np.nan).mode()\n",
    "\n",
    "# TNNormDeaths_mean = round(StNormDeaths_week[\"TN\"].mean())\n",
    "# TNNormDeaths_median = round(StNormDeaths_week[\"TN\"].median())\n",
    "# TNNormDeaths_mode = StNormDeaths_week[\"TN\"].mode()\n",
    "# TNNormDeaths0_mode = StNormDeaths_week[\"TN\"].replace(0, np.nan).mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Cases_statistics =[[AZNormDeaths_mean, INNormDeaths_mean, MANormDeaths_mean, MONormDeaths_mean, NJNormDeaths_mean, TNNormDeaths_mean],\n",
    "             [AZNormDeaths_median,INNormDeaths_median, MANormDeaths_median, MONormDeaths_median, NJNormDeaths_median, TNNormDeaths_median],\n",
    "             [AZNormDeaths_mode[0],INNormDeaths_mode[0],MANormDeaths_mode[0],MONormDeaths_mode[0],NJNormDeaths_mode[0],TNNormDeaths_mode[0]]]\n",
    "\n",
    "\n",
    "#Create a dataframe from list\n",
    "\n",
    "Cases_sta = pd.DataFrame(Cases_statistics, columns = ['AZ', 'IN', 'MA','MO', 'NJ', 'TN'], \n",
    "                         index=['Mean', 'Median', 'Mode'])  \n",
    "Cases_sta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NJ has the highest mean of new deaths and the difference between its median and its mean is remarkable compare to other states which shows the peak is close to the left side of the graph. IN, TN and MO have the lowest Mean but the mean, median and mode of IN are equal which demonestrate that  the distribution of new cases in IN as approximately symmetrical. For some period of time mode = 0 indicates that the state was successful to minimize the number of deathes for a greater number of weeks, however it was temporery."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify counties within the previous state with high case and death rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select counties for MA\n",
    "\n",
    "MACounties = covid_df.loc[covid_df['State'] == \"MA\"]\n",
    "MACounties.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add a new column to MA dataset which shows total confirmed cases for each county\n",
    "MACounties['Total Cases']= MACounties[\"10/19/20_x\"]\n",
    "\n",
    "#add a new column to MA dataset which shows total death for each county\n",
    "MACounties['Total Death']= MACounties[\"10/19/20_y\"]\n",
    "MACounties.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Highest rate of cases in MA counties\n",
    "\n",
    "highest_rateCases_MA = MACounties[['County Name', \"population\", \"Total Cases\"]] \n",
    "highest_rateCases_MA[\"Rate of Cases\"] = ((highest_rateCases_MA[\"Total Cases\"]/highest_rateCases_MA[\"population\"])*100000).round()\n",
    "highest_rateCases_MA = highest_rateCases_MA.sort_values(['Rate of Cases'], ascending = False) \n",
    "highest_rateCases_MA.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Highest rate of death in MA counties without normalizing\n",
    "\n",
    "highest_rateDeath_MA = MACounties[['County Name', \"population\", \"Total Death\"]] \n",
    "highest_rateDeath_MA[\"Rate of Death\"] = ((highest_rateDeath_MA[\"Total Death\"]/highest_rateDeath_MA[\"population\"])*100000).round()\n",
    "highest_rateDeath_MA = highest_rateDeath_MA.sort_values(['Rate of Death'], ascending = False) \n",
    "highest_rateDeath_MA.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot daily trends (cases and deaths, new cases) of state and top 5 infected counties. Utilize aggregrate, normalized by population, and log normalized values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stateMAST= covid_dfSt.transpose()\n",
    "MA = stateMAST[19]\n",
    "MA_NewCases = MA.filter(regex = \"x\").to_frame()\n",
    "MA_NewDeaths = MA.filter(regex = \"y\").to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select counties with highest rate of cases \n",
    "MACounties_caseRate = MACounties.loc[(MACounties['County Name']==\"Suffolk County\") | (MACounties['County Name']==\"Essex County\")\n",
    "                             | (MACounties['County Name']==\"Plymouth County\")| (MACounties['County Name']==\"Bristol County\")\n",
    "                             | (MACounties['County Name']==\"Middlesex County\")]\n",
    "MACounties_caseRate.drop(columns = \"County Name_y\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select number of Cases\n",
    "CountiesCases = MACounties_caseRate.filter(regex = \"x\")\n",
    "CountiesCases = CountiesCases.transpose()\n",
    "\n",
    "#Rename columns\n",
    "CountiesCases.columns = ['Bristol County', 'Essex County','Middlesex County','Plymouth County'\n",
    "                         ,'Suffolk County']\n",
    "CountiesCases.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate new Cases for highest rated counties\n",
    "\n",
    "CountiesNewCases = CountiesCases.diff()\n",
    "MA_NewCases = MA_NewCases.diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenate two MA dataframe with counties dataframe\n",
    "\n",
    "dailyTrendsCases = pd.concat([MA_NewCases, CountiesNewCases], axis=1)\n",
    "dailyTrendsCases.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize new cases\n",
    "\n",
    "dailyTrendsCases[\"MA Cases(Norm)\"] = (((dailyTrendsCases[19]/6892503)*300000).astype(float)).round()\n",
    "dailyTrendsCases[\"Bristol Cases(Norm)\"] = ((dailyTrendsCases[\"Bristol County\"]/565217)*300000).round()\n",
    "dailyTrendsCases[\"Essex Cases(Norm)\"] = ((dailyTrendsCases[\"Essex County\"]/789034)*300000).round()\n",
    "dailyTrendsCases[\"Middlesex Cases(Norm)\"] = ((dailyTrendsCases[\"Middlesex County\"]/1611699)*300000).round()\n",
    "dailyTrendsCases[\"Plymouth Cases(Norm)\"] = ((dailyTrendsCases[\"Plymouth County\"]/521202)*300000).round()\n",
    "dailyTrendsCases[\"Suffolk Cases(Norm)\"] = ((dailyTrendsCases[\"Suffolk County\"]/803907)*300000).round()\n",
    "\n",
    "\n",
    "#Drop unnecessary columns \n",
    "dailyTrendsCases.drop(columns =[19,\"Bristol County\", \"Essex County\", \"Middlesex County\", \"Plymouth County\",\n",
    "                               \"Suffolk County\"], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Daily Trends ( New Cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Plotting Daily trends \n",
    "\n",
    "trace0 = go.Scatter(x=dailyTrendsCases.index, y=dailyTrendsCases[\"MA Cases(Norm)\"], \n",
    "                    name=\"MA\", \n",
    "                    mode=\"lines+markers\") \n",
    "\n",
    "trace1 = go.Scatter(x=dailyTrendsCases.index, y=dailyTrendsCases[\"Bristol Cases(Norm)\"], \n",
    "                    name=\"Bristol\", \n",
    "                    mode=\"lines+markers\")  \n",
    "\n",
    "trace2 = go.Scatter(x=dailyTrendsCases.index, y=dailyTrendsCases[\"Essex Cases(Norm)\"], \n",
    "                    name=\"Essex\", \n",
    "                    mode=\"lines+markers\") \n",
    "\n",
    "trace3 = go.Scatter(x=dailyTrendsCases.index, y=dailyTrendsCases[\"Middlesex Cases(Norm)\"], \n",
    "                    name=\"Middlesex\", \n",
    "                    mode=\"lines+markers\") \n",
    "\n",
    "trace4 = go.Scatter(x=dailyTrendsCases.index, y=dailyTrendsCases[\"Plymouth Cases(Norm)\"], \n",
    "                    name=\"Plymouth\", \n",
    "                    mode=\"lines+markers\") \n",
    "\n",
    "trace5 = go.Scatter(x=dailyTrendsCases.index, y=dailyTrendsCases[\"Suffolk Cases(Norm)\"], \n",
    "                    name=\"Suffolk\", \n",
    "                    mode=\"lines+markers\") \n",
    "\n",
    "\n",
    "mydata = go.Data([trace0, trace1,trace2, trace3,trace4,trace5])\n",
    "\n",
    "mylayout = go.Layout(\n",
    "    title=\"\"\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=mydata, layout=mylayout)\n",
    "\n",
    "plotly.offline.iplot(fig, filename = '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New Deaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select counties with highest rate of cases \n",
    "MACounties_deathsRate = MACounties.loc[(MACounties['County Name']==\"Essex County\") | (MACounties['County Name']==\"Hampden County\")\n",
    "                             | (MACounties['County Name']==\"Norfolk County\")| (MACounties['County Name']==\"Plymouth County\")\n",
    "                             | (MACounties['County Name']==\"Suffolk County\")]\n",
    "MACounties_deathsRate.drop(columns = \"County Name_y\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select number of Deaths\n",
    "CountiesDeaths = MACounties_deathsRate.filter(regex = \"_y\")\n",
    "CountiesDeaths = CountiesDeaths.transpose()\n",
    "\n",
    "#Rename columns\n",
    "CountiesDeaths.columns = ['Essex County', 'Hampden County','Norfolk County','Plymouth County'\n",
    "                         ,'Suffolk County']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate new Deaths for highest rated counties\n",
    "\n",
    "CountiesNewDeaths = CountiesDeaths.diff()\n",
    "MA_NewDeaths = MA_NewDeaths.diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenate two MA dataframe with counties dataframe\n",
    "\n",
    "dailyTrendsDeaths = pd.concat([MA_NewDeaths, CountiesNewDeaths], axis=1)\n",
    "dailyTrendsDeaths.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize new deaths\n",
    "\n",
    "dailyTrendsDeaths[\"MA Deaths(Norm)\"] = (((dailyTrendsDeaths[19]/6892503)*300000).astype(float)).round()\n",
    "dailyTrendsDeaths[\"Essex Cases(Norm)\"] = ((dailyTrendsDeaths[\"Essex County\"]/789034)*300000).round()\n",
    "dailyTrendsDeaths[\"Hampden Cases(Norm)\"] = ((dailyTrendsDeaths[\"Hampden County\"]/466372)*300000).round()\n",
    "dailyTrendsDeaths[\"Norfolk Cases(Norm)\"] = ((dailyTrendsDeaths[\"Norfolk County\"]/706775)*300000).round()\n",
    "dailyTrendsDeaths[\"Plymouth Cases(Norm)\"] = ((dailyTrendsDeaths[\"Plymouth County\"]/521202)*300000).round()\n",
    "dailyTrendsDeaths[\"Suffolk Cases(Norm)\"] = ((dailyTrendsDeaths[\"Suffolk County\"]/803907)*300000).round()\n",
    "\n",
    "#Drop unnecessary columns \n",
    "dailyTrendsDeaths.drop(columns =[19, \"Essex County\", \"Hampden County\", \"Norfolk County\", \"Plymouth County\",\n",
    "                               \"Suffolk County\"], inplace = True)\n",
    "dailyTrendsDeaths.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Daily Trends (New Deaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting Daily trends \n",
    "\n",
    "trace0 = go.Scatter(x=dailyTrendsDeaths.index, y=dailyTrendsDeaths[\"MA Deaths(Norm)\"], \n",
    "                    name=\"MA\", \n",
    "                    mode=\"lines+markers\") \n",
    "\n",
    "trace1 = go.Scatter(x=dailyTrendsDeaths.index, y=dailyTrendsDeaths[\"Essex Cases(Norm)\"], \n",
    "                    name=\"Essex\", \n",
    "                    mode=\"lines+markers\")  \n",
    "\n",
    "trace2 = go.Scatter(x=dailyTrendsDeaths.index, y=dailyTrendsDeaths[\"Hampden Cases(Norm)\"], \n",
    "                    name=\"Hampden\", \n",
    "                    mode=\"lines+markers\") \n",
    "\n",
    "trace3 = go.Scatter(x=dailyTrendsDeaths.index, y=dailyTrendsDeaths[\"Norfolk Cases(Norm)\"], \n",
    "                    name=\"Norfolk\", \n",
    "                    mode=\"lines+markers\") \n",
    "\n",
    "trace4 = go.Scatter(x=dailyTrendsDeaths.index, y=dailyTrendsDeaths[\"Plymouth Cases(Norm)\"], \n",
    "                    name=\"Plymouth\", \n",
    "                    mode=\"lines+markers\") \n",
    "\n",
    "trace5 = go.Scatter(x=dailyTrendsDeaths.index, y=dailyTrendsDeaths[\"Suffolk Cases(Norm)\"], \n",
    "                    name=\"Suffolk\", \n",
    "                    mode=\"lines+markers\") \n",
    "\n",
    "\n",
    "mydata = go.Data([trace0, trace1,trace2, trace3,trace4,trace5])\n",
    "\n",
    "mylayout = go.Layout(\n",
    "    title=\"\"\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=mydata, layout=mylayout)\n",
    "\n",
    "plotly.offline.iplot(fig, filename = '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit a distribution to the number of COVID-19 cases of a state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graphically plot the distribution and describe the distribution statistics. If using discrete values, calculate the Probability Mass Function for the individual values or range (if using histogram) and plot that. What do we need to plot here?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model a poission distribution of COVID-19 cases and deaths of a state and compare to other 5 states."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalizing Data by per 1000000 people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# StNormCases_week\n",
    "# StNormDeaths_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate mean of cases for each state \n",
    "\n",
    "STCasesMean = StNormCases_week.mean().round().astype(int)\n",
    "STCasesMean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate mean of deaths for each state \n",
    "\n",
    "STDeathsMean = StNormDeaths_week.mean().round()\n",
    "STDeathsMean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate different K for different states for cases\n",
    "\n",
    "K = [50,60,70,80,90,100,120,130]\n",
    "AZ = []\n",
    "IN = []\n",
    "MA = []\n",
    "MO = []\n",
    "NJ = []\n",
    "TN = []\n",
    "\n",
    "# append calculated k to each corresponding list\n",
    "for num in K:\n",
    "    PMF = stats.poisson.pmf(k=num, mu=STCasesMean[\"AZ\"]).round(4)\n",
    "    AZ.append(PMF)\n",
    "    \n",
    "for num in K:\n",
    "    PMF = stats.poisson.pmf(k=num, mu=STCasesMean[\"IN\"]).round(4)\n",
    "    IN.append(PMF)\n",
    "\n",
    "for num in K:\n",
    "    PMF = stats.poisson.pmf(k=num, mu=STCasesMean[\"MA\"]).round(4)\n",
    "    MA.append(PMF)\n",
    "    \n",
    "for num in K:\n",
    "    PMF = stats.poisson.pmf(k=num, mu=STCasesMean[\"MO\"]).round(4)\n",
    "    MO.append(PMF)\n",
    "\n",
    "for num in K:\n",
    "    PMF = stats.poisson.pmf(k=num, mu=STCasesMean[\"NJ\"]).round(4)\n",
    "    NJ.append(PMF)\n",
    "    \n",
    "for num in K:\n",
    "    PMF = stats.poisson.pmf(k=num, mu=STCasesMean[\"TN\"]).round(4)\n",
    "    TN.append(PMF)\n",
    "    \n",
    "#create a dataframe from lists\n",
    "dfCases = pd.DataFrame(list(zip(K, AZ, IN, MA, MO, NJ, TN)), columns =['k','AZ', 'IN', 'MA', 'MO', 'NJ', 'TN'])\n",
    "dfCases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate different K for different states for cases\n",
    "\n",
    "KDeaths = [0,1,2,3,4,5,6,7]\n",
    "AZdeaths = []\n",
    "INdeaths = []\n",
    "MAdeaths = []\n",
    "MOdeaths = []\n",
    "NJdeaths = []\n",
    "TNdeaths = []\n",
    "\n",
    "# append calculated k to each corresponding list\n",
    "for num in KDeaths:\n",
    "    PMF = stats.poisson.pmf(k=num, mu=STDeathsMean[\"AZ\"]).round(4)\n",
    "    AZdeaths.append(PMF)\n",
    "    \n",
    "for num in KDeaths:\n",
    "    PMF = stats.poisson.pmf(k=num, mu=STDeathsMean[\"IN\"]).round(4)\n",
    "    INdeaths.append(PMF)\n",
    "\n",
    "for num in KDeaths:\n",
    "    PMF = stats.poisson.pmf(k=num, mu=STDeathsMean[\"MA\"]).round(4)\n",
    "    MAdeaths.append(PMF)\n",
    "    \n",
    "for num in KDeaths:\n",
    "    PMF = stats.poisson.pmf(k=num, mu=STDeathsMean[\"MO\"]).round(4)\n",
    "    MOdeaths.append(PMF)\n",
    "\n",
    "for num in KDeaths:\n",
    "    PMF = stats.poisson.pmf(k=num, mu=STDeathsMean[\"NJ\"]).round(4)\n",
    "    NJdeaths.append(PMF)\n",
    "    \n",
    "for num in KDeaths:\n",
    "    PMF = stats.poisson.pmf(k=num, mu=STDeathsMean[\"TN\"]).round(4)\n",
    "    TNdeaths.append(PMF)\n",
    "    \n",
    "#create a dataframe from lists\n",
    "dfDeaths = pd.DataFrame(list(zip(KDeaths, AZdeaths, INdeaths, MAdeaths, MOdeaths, NJdeaths, TNdeaths)),\n",
    "                  columns =['k','AZ', 'IN', 'MA', 'MO', 'NJ', 'TN'])\n",
    "dfDeaths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model poission distributions for North Carolina counties COVID-19 in cases and deaths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select rows which are for NC\n",
    "\n",
    "covid_dfNC = covid_df.loc[covid_df['State'] == \"NC\"]\n",
    "covid_dfNC = covid_dfNC.drop(columns = \"County Name_y\")\n",
    "covid_dfNC.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seperate covid_dfNC to cases number and deaths number\n",
    "\n",
    "NCcases = covid_dfNC.filter(regex = \"x\")\n",
    "NCdeaths = covid_dfNC.filter(regex = \"_y\")\n",
    "\n",
    "NCcases.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculae new cases and new deaths\n",
    "\n",
    "NCNewCases = NCcases.diff(axis = 1)\n",
    "NCNewDeaths = NCdeaths.diff(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize new cases\n",
    "\n",
    "NCNormCases = NCNewCases.transpose()\n",
    "NCCounties = covid_dfNC[\"County Name\"].tolist()\n",
    "NCNormCases.columns = NCCounties\n",
    "CountiesPopulation = covid_dfNC[\"population\"].tolist()\n",
    "NCNormCases = NCNormCases.rename(columns={col: col.split(' ')[0] for col in NCNormCases.columns})\n",
    "counties = NCNormCases.columns.tolist()\n",
    "ExColumns = (NCNormCases.columns).tolist()\n",
    "\n",
    "for i in range(len(NCNormCases.columns)):\n",
    "    NCNormCases[NCNormCases.columns[i]+\" Cases(Norm)\"]=((NCNormCases[NCNormCases.columns[i]]/CountiesPopulation[i])*30000).round()\n",
    "\n",
    "NCNormCases.drop(columns =ExColumns, inplace = True)\n",
    "\n",
    "\n",
    "# Normalize new cases\n",
    "\n",
    "NCNormDeaths = NCNewDeaths.transpose()\n",
    "# # NCCounties = covid_dfNC[\"County Name\"].tolist()\n",
    "NCNormDeaths.columns = NCCounties\n",
    "# # CountiesPopulation = covid_dfNC[\"population\"].tolist()\n",
    "NCNormDeaths = NCNormDeaths.rename(columns={col: col.split(' ')[0] for col in NCNormDeaths.columns})\n",
    "ExColumns = (NCNormDeaths.columns).tolist()\n",
    "\n",
    "for i in range(len(NCNormDeaths.columns)):\n",
    "    NCNormDeaths[NCNormDeaths.columns[i]+\" Deaths(Norm)\"]=((NCNormDeaths[NCNormDeaths.columns[i]]/CountiesPopulation[i])*30000).round()\n",
    "\n",
    "NCNormDeaths.drop(columns =ExColumns, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate weekly mean for Normalized New Cases\n",
    "\n",
    "NCNormCases_week = NCNormCases.groupby(np.arange(len(NCNormCases))//7).mean().round(0).astype(int).rename_axis('Week')\n",
    "\n",
    "NCNormCases_week = NCNormCases_week.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate weekly mean for Normalized New Deaths\n",
    "\n",
    "NCNormDeaths_week = NCNormDeaths.groupby(np.arange(len(NCNormDeaths))//7).mean().round(0).astype(int).rename_axis('Week')\n",
    "\n",
    "NCNormDeaths_week = NCNormDeaths_week.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean of cases for each county\n",
    "NCNormCases_mean = NCNormCases_week.mean().round()\n",
    "\n",
    "#Calculate mean of deaths for each county \n",
    "NCNormDeaths_mean = NCNormDeaths_week.mean().round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model poisoon for different K for different states for cases\n",
    "\n",
    "K = [0,1,2,3,4]\n",
    "NC = []\n",
    "\n",
    "\n",
    "# append calculated k to each corresponding list\n",
    "for county in counties:\n",
    "    countyK = []\n",
    "    for num in K:\n",
    "        PMF = stats.poisson.pmf(k=num, mu=NCNormCases_mean[county +\" Cases(Norm)\"]).round(4)\n",
    "        countyK.append(PMF)\n",
    "    NC.append(countyK)\n",
    "          \n",
    "# NC\n",
    "\n",
    "# #create a dataframe from lists\n",
    "\n",
    "NCCases = pd.DataFrame(NC, columns = ['K=0', 'K=1', 'K=2','K=3','K=4']) \n",
    "NCCases[\"County Name\"] = counties\n",
    "NCCases.set_index(\"County Name\", inplace = True)\n",
    "NCCases.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model poisoon for different K for different states for deaths\n",
    "\n",
    "K = [0,1,2,3,4]\n",
    "NCD = []\n",
    "\n",
    "\n",
    "# append calculated k to each corresponding list\n",
    "for county in counties:\n",
    "    countyK = []\n",
    "    for num in K:\n",
    "        PMF = stats.poisson.pmf(k=num, mu=NCNormDeaths_week[county +\" Deaths(Norm)\"]).round(4)\n",
    "        countyK.append(PMF)\n",
    "    NCD.append(countyK)\n",
    "          \n",
    "# NC\n",
    "\n",
    "# #create a dataframe from lists\n",
    "\n",
    "NCDeaths = pd.DataFrame(NC, columns = ['K=0', 'K=1', 'K=2','K=3','K=4']) \n",
    "NCDeaths[\"County Name\"] = counties\n",
    "NCDeaths.set_index(\"County Name\", inplace = True)\n",
    "NCDeaths.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform corelation between Enrichment data valiables and COVID-19 cases to observe any patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read csv file \n",
    "demographic_df = pd.read_csv(\"../../../data/Demographic.csv\")\n",
    "\n",
    "# Remove columns which shows margin of errors, percent estimate and percent margin of error \n",
    "demographic_df = demographic_df[demographic_df.columns.drop(list(demographic_df.filter(regex='Margin')))]\n",
    "demographic_df = demographic_df[demographic_df.columns.drop(list(demographic_df.filter(regex='Percent')))]\n",
    "demographic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select county FIPS from is columns and append them in the list and create new column with the list \n",
    "\n",
    "county_FIPS_list = []\n",
    "for i in range(len(demographic_df[\"id\"])):\n",
    "    county_FIPS_list.append(demographic_df.loc[i,'id'][9:])\n",
    "    \n",
    "demographic_df[\"countyFIPS\"] = county_FIPS_list\n",
    "\n",
    "# convert the type of countyFIPS from string to int\n",
    "demographic_df['countyFIPS'] = demographic_df['countyFIPS'].astype(int)\n",
    "\n",
    "# Split geographical area name into county and state name\n",
    "demographic_df[['County Name','State']] = demographic_df[\"Geographic Area Name\"].str.split(\",\",expand=True)\n",
    "\n",
    "demographic_df.drop(columns = ['id', 'Geographic Area Name'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
